{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Disclaimer\n### This dataset was published on Kaggle by <a href=\"https://www.kaggle.com/blackmoon\">АнатолийБельчиков</a>. It was used by <a href=\"https://www.kaggle.com/andrewkalita\">me</a> just as an example of text classification in Russian language. If you speak Russian and this corpus unacceptable for you to read, please visit <a href=\"https://www.google.com/search?q=котики&tbm=isch\">this site</a>.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import metrics\n\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('averaged_perceptron_tagger_ru')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfComments = pd.read_csv('../input/russian-language-toxic-comments/labeled.csv')\ndfComments.head(10)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfComments.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"desc = dfComments.groupby('toxic').describe()\n\nplt.bar('0', desc['comment']['count'][0], label=\"Non toxical comment\", color='green')\nplt.bar('1', desc['comment']['count'][1], label=\"Toxical comment\", color='red')\nplt.legend()\nplt.ylabel('Number of comments')\nplt.title('Comment groups')\nplt.show()\n\nprint('Comment description\\n')\nprint(desc)\nprint()\nprint(dfComments.describe())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n\nax1.hist(dfComments[dfComments['toxic']==0]['comment'].str.len() ,color='green')\nax1.set_title('non toxic')\n\nax2.hist(dfComments[dfComments['toxic']==1]['comment'].str.len() ,color='red')\nax2.set_title('toxic')\n\nfig.suptitle('Characters in comments')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n\nax1.hist(dfComments[dfComments['toxic']==0]['comment'].str.split().map(lambda x: len(x)) ,color='green')\nax1.set_title('non toxic')\n\nax2.hist(dfComments[dfComments['toxic']==1]['comment'].str.split().map(lambda x: len(x)) ,color='red')\nax2.set_title('toxic')\n\nfig.suptitle('Words in comments')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preporation","metadata":{}},{"cell_type":"code","source":"text = np.array(dfComments.comment.values)\ntarget = dfComments.toxic.astype(int).values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def upperCaseRate(string):\n    \"Returns percentage of uppercase letters in the string\"\n    return np.array(list(map(str.isupper, string))).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"upcaseRate = list(map(upperCaseRate, dfComments.comment.values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanText(string):\n    \"\"\"This function deletes all symbols except Cyrilic and Base Latin alphabet,\n    stopwords, functional parts of speech. Returns string of words stem.\"\"\"\n    # Common cleaning\n    string = string.lower()\n    string = re.sub(r\"http\\S+\", \"\", string)\n    string = str.replace(string,'Ё','е')\n    string = str.replace(string,'ё','е')\n    prog = re.compile('[А-Яа-яA-Za-z]+')\n    words = prog.findall(string.lower())\n    \n    # Word Cleaning\n    ## Stop Words\n    stopwords = nltk.corpus.stopwords.words('russian')\n    words = [w for w in words if w not in stopwords]\n    ## Cleaning functional POS (Parts of Speech)\n    functionalPos = {'CONJ', 'PRCL'}\n    words = [w for w, pos in nltk.pos_tag(words, lang='rus') if pos not in functionalPos]\n    ## Stemming\n    stemmer = SnowballStemmer('russian')\n    return ' '.join(list(map(stemmer.stem, words)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntext = list(map(cleanText, text))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Proccessing","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=.3, stratify=target, shuffle = True, random_state=0)\nprint('Dim of train:', len(X_train), '\\tTarget rate: {:.2f}%'.format(y_train.mean()))\nprint(\"Dim of test:\", len(X_test), '\\tTarget rate: {:.2f}%'.format(y_test.mean()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline","metadata":{}},{"cell_type":"code","source":"clf_pipeline = Pipeline(\n            [(\"vectorizer\", TfidfVectorizer()), # Prod feature: tokenizer=cleanText\n            (\"classifier\", LinearSVC())]\n        )\n\nclf_pipeline.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = metrics.confusion_matrix(y_test, clf_pipeline.predict(X_test))\n\ndef plotConfusionMatrix(cm):\n    fig = plt.figure(figsize=(7,7))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion Matrix')\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return None\n\nplotConfusionMatrix(cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(y_test, clf_pipeline.predict(X_test)))\nf1_base = metrics.f1_score(y_test, clf_pipeline.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adjusts","metadata":{}},{"cell_type":"code","source":"print('\\n'.join(clf_pipeline.get_params().keys()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters = {'vectorizer__max_features': (10**3, 10**4),\n              'vectorizer__ngram_range': ((1, 2),(2, 3)),\n              'classifier__penalty': ('l1','l2'),\n              'classifier__C': (range(1,10,2))\n             }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ngs_clf = GridSearchCV(clf_pipeline, parameters, scoring='f1', cv = 4, n_jobs=-1)\ngs_clf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(y_test, gs_clf.predict(X_test)))\nf1_gsLSVC = metrics.f1_score(y_test, gs_clf.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Randomized Search CV on TfidfVectorizer and LogisticRegression","metadata":{}},{"cell_type":"code","source":"parameters = { #'vectorizer__max_features': (10**2, 10**3),\n              'vectorizer__ngram_range': [(1, 2),(1, 3)],\n              'vectorizer__min_df': [0.,.2,.4,.6,.8,1],\n              'classifier__penalty': ('l1','l2'),\n              'classifier__C': (range(1,10,2)),\n             }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_pipeline_LogitReg = Pipeline(\n            [(\"vectorizer\", TfidfVectorizer()),\n            (\"classifier\", LogisticRegression())]\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotROC(y_test, probs, titl=''):\n    if titl!='':\n        titl = ' ('+titl+')' \n    fpr, tpr, threshold = metrics.roc_curve(y_test, probs)\n    roc_auc = metrics.auc(fpr, tpr)\n    plt.title('Receiver Operating Characteristic'+titl)\n    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.5f' % roc_auc)\n    plt.legend(loc = 'lower right')\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.show()\n    return None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nrndgs_clf_LogitReg = RandomizedSearchCV(clf_pipeline_LogitReg, parameters, scoring='f1', cv = 4, n_jobs=-1)\nrndgs_clf_LogitReg.fit(X_train, y_train)\n\nprobs = rndgs_clf_LogitReg.predict_proba(X_train)[:,1]\nplotROC(y_train, probs, 'Train')\n\nprobs = rndgs_clf_LogitReg.predict_proba(X_test)[:,1]\nplotROC(y_test, probs, 'Test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks like overfited model. There's too high AUC on train.","metadata":{}},{"cell_type":"code","source":"plotConfusionMatrix(metrics.confusion_matrix(y_test, rndgs_clf_LogitReg.predict(X_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(y_test, rndgs_clf_LogitReg.predict(X_test)))\nf1_rndLogR = metrics.f1_score(y_test, rndgs_clf_LogitReg.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add more parameters","metadata":{}},{"cell_type":"code","source":"%%time\nparameters = {'vectorizer__max_features': (10**2, 10**3),\n              'vectorizer__ngram_range': [(1, 2),(1, 3)],\n              'vectorizer__min_df': [0.,.2,.4,.6,.8,1],\n              'classifier__penalty': ('l1','l2'),\n              'classifier__C': (range(1,10,2)),\n             }\n\nclf_pipeline_LogitReg = Pipeline(\n            [(\"vectorizer\", TfidfVectorizer()),\n            (\"classifier\", LogisticRegression())]\n        )\n\nrndgs_clf_LogitReg = RandomizedSearchCV(clf_pipeline_LogitReg, parameters, scoring='f1', cv = 4, n_jobs=-1)\nrndgs_clf_LogitReg.fit(X_train, y_train)\n\nprobs = rndgs_clf_LogitReg.predict_proba(X_train)[:,1]\nplotROC(y_train, probs, 'Train')\n\nprobs = rndgs_clf_LogitReg.predict_proba(X_test)[:,1]\nplotROC(y_test, probs, 'Test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(metrics.classification_report(y_test, rndgs_clf_LogitReg.predict(X_test)))\nf1_rndLogR_2 = metrics.f1_score(y_test, rndgs_clf_LogitReg.predict(X_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame([f1_base, f1_gsLSVC, f1_rndLogR, f1_rndLogR_2], index=['BaseLine', 'GS_LSVC', 'rndGS_LogR', 'rndGS_LogR_Adj'], columns=['f1 score'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline algorithm looks simple and good enough. The Confusion Matrix isn't bad too. Howewer, the Logistic Regression forecasts probubilities of classification. Hence, we are able to plot Reciever Operator Curve (ROC) and get AUC (Area under Curve) value. It may be a useful for the next improvements of this notebook.","metadata":{}}]}