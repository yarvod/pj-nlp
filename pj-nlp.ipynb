{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.svm import LinearSVC\n","from sklearn import model_selection\n","from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn import metrics\n","\n","import nltk\n","from nltk.stem.snowball import SnowballStemmer\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading averaged_perceptron_tagger_ru: <urlopen\n","[nltk_data]     error [SSL: CERTIFICATE_VERIFY_FAILED] certificate\n","[nltk_data]     verify failed: unable to get local issuer certificate\n","[nltk_data]     (_ssl.c:1129)>\n"]},{"data":{"text/plain":["False"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('averaged_perceptron_tagger_ru')"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Собаке - собачья смерть\\n</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Для каких стан является эталоном современная с...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Ебать тебя разносит, шизик.\\n</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Обосрался, сиди обтекай\\n</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                             comment  toxic\n","0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n","1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n","2                          Собаке - собачья смерть\\n    1.0\n","3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n","4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n","5  Для каких стан является эталоном современная с...    1.0\n","6  В шапке были ссылки на инфу по текущему фильму...    0.0\n","7  УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...    1.0\n","8                      Ебать тебя разносит, шизик.\\n    1.0\n","9                          Обосрался, сиди обтекай\\n    1.0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["dfComments = pd.read_csv('data/labeled.csv')\n","dfComments.head(10)"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'dfComments' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dfComments\u001b[39m.\u001b[39mtail(\u001b[39m10\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'dfComments' is not defined"]}],"source":["dfComments.tail(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["desc = dfComments.groupby('toxic').describe()\n","\n","plt.bar('0', desc['comment']['count'][0], label=\"Non toxical comment\", color='green')\n","plt.bar('1', desc['comment']['count'][1], label=\"Toxical comment\", color='red')\n","plt.legend()\n","plt.ylabel('Number of comments')\n","plt.title('Comment groups')\n","plt.show()\n","\n","print('Comment description\\n')\n","print(desc)\n","print()\n","print(dfComments.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n","\n","ax1.hist(dfComments[dfComments['toxic']==0]['comment'].str.len() ,color='green')\n","ax1.set_title('non toxic')\n","\n","ax2.hist(dfComments[dfComments['toxic']==1]['comment'].str.len() ,color='red')\n","ax2.set_title('toxic')\n","\n","fig.suptitle('Characters in comments')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n","\n","ax1.hist(dfComments[dfComments['toxic']==0]['comment'].str.split().map(lambda x: len(x)) ,color='green')\n","ax1.set_title('non toxic')\n","\n","ax2.hist(dfComments[dfComments['toxic']==1]['comment'].str.split().map(lambda x: len(x)) ,color='red')\n","ax2.set_title('toxic')\n","\n","fig.suptitle('Words in comments')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Preporation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = np.array(dfComments.comment.values)\n","target = dfComments.toxic.astype(int).values"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def upperCaseRate(string):\n","    \"Returns percentage of uppercase letters in the string\"\n","    return np.array(list(map(str.isupper, string))).mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["upcaseRate = list(map(upperCaseRate, dfComments.comment.values))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def cleanText(string):\n","    \"\"\"This function deletes all symbols except Cyrilic and Base Latin alphabet,\n","    stopwords, functional parts of speech. Returns string of words stem.\"\"\"\n","    # Common cleaning\n","    string = string.lower()\n","    string = re.sub(r\"http\\S+\", \"\", string)\n","    string = str.replace(string,'Ё','е')\n","    string = str.replace(string,'ё','е')\n","    prog = re.compile('[А-Яа-яA-Za-z]+')\n","    words = prog.findall(string.lower())\n","    \n","    # Word Cleaning\n","    ## Stop Words\n","    stopwords = nltk.corpus.stopwords.words('russian')\n","    words = [w for w in words if w not in stopwords]\n","    ## Cleaning functional POS (Parts of Speech)\n","    functionalPos = {'CONJ', 'PRCL'}\n","    words = [w for w, pos in nltk.pos_tag(words, lang='rus') if pos not in functionalPos]\n","    ## Stemming\n","    stemmer = SnowballStemmer('russian')\n","    return ' '.join(list(map(stemmer.stem, words)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","text = list(map(cleanText, text))"]},{"cell_type":"markdown","metadata":{},"source":["## Proccessing"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=.3, stratify=target, shuffle = True, random_state=0)\n","print('Dim of train:', len(X_train), '\\tTarget rate: {:.2f}%'.format(y_train.mean()))\n","print(\"Dim of test:\", len(X_test), '\\tTarget rate: {:.2f}%'.format(y_test.mean()))"]},{"cell_type":"markdown","metadata":{},"source":["## Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clf_pipeline = Pipeline(\n","            [(\"vectorizer\", TfidfVectorizer()), # Prod feature: tokenizer=cleanText\n","            (\"classifier\", LinearSVC())]\n","        )\n","\n","clf_pipeline.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = metrics.confusion_matrix(y_test, clf_pipeline.predict(X_test))\n","\n","def plotConfusionMatrix(cm):\n","    fig = plt.figure(figsize=(7,7))\n","    sns.heatmap(cm, annot=True, fmt=\"d\")\n","    plt.title('Confusion Matrix')\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    return None\n","\n","plotConfusionMatrix(cm)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(metrics.classification_report(y_test, clf_pipeline.predict(X_test)))\n","f1_base = metrics.f1_score(y_test, clf_pipeline.predict(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["## Adjusts"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print('\\n'.join(clf_pipeline.get_params().keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["parameters = {'vectorizer__max_features': (10**3, 10**4),\n","              'vectorizer__ngram_range': ((1, 2),(2, 3)),\n","              'classifier__penalty': ('l1','l2'),\n","              'classifier__C': (range(1,10,2))\n","             }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","gs_clf = GridSearchCV(clf_pipeline, parameters, scoring='f1', cv = 4, n_jobs=-1)\n","gs_clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(metrics.classification_report(y_test, gs_clf.predict(X_test)))\n","f1_gsLSVC = metrics.f1_score(y_test, gs_clf.predict(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["### Randomized Search CV on TfidfVectorizer and LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["parameters = { #'vectorizer__max_features': (10**2, 10**3),\n","              'vectorizer__ngram_range': [(1, 2),(1, 3)],\n","              'vectorizer__min_df': [0.,.2,.4,.6,.8,1],\n","              'classifier__penalty': ('l1','l2'),\n","              'classifier__C': (range(1,10,2)),\n","             }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["clf_pipeline_LogitReg = Pipeline(\n","            [(\"vectorizer\", TfidfVectorizer()),\n","            (\"classifier\", LogisticRegression())]\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plotROC(y_test, probs, titl=''):\n","    if titl!='':\n","        titl = ' ('+titl+')' \n","    fpr, tpr, threshold = metrics.roc_curve(y_test, probs)\n","    roc_auc = metrics.auc(fpr, tpr)\n","    plt.title('Receiver Operating Characteristic'+titl)\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.5f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","rndgs_clf_LogitReg = RandomizedSearchCV(clf_pipeline_LogitReg, parameters, scoring='f1', cv = 4, n_jobs=-1)\n","rndgs_clf_LogitReg.fit(X_train, y_train)\n","\n","probs = rndgs_clf_LogitReg.predict_proba(X_train)[:,1]\n","plotROC(y_train, probs, 'Train')\n","\n","probs = rndgs_clf_LogitReg.predict_proba(X_test)[:,1]\n","plotROC(y_test, probs, 'Test')"]},{"cell_type":"markdown","metadata":{},"source":["Looks like overfited model. There's too high AUC on train."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plotConfusionMatrix(metrics.confusion_matrix(y_test, rndgs_clf_LogitReg.predict(X_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(metrics.classification_report(y_test, rndgs_clf_LogitReg.predict(X_test)))\n","f1_rndLogR = metrics.f1_score(y_test, rndgs_clf_LogitReg.predict(X_test))"]},{"cell_type":"markdown","metadata":{},"source":["### Add more parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","parameters = {'vectorizer__max_features': (10**2, 10**3),\n","              'vectorizer__ngram_range': [(1, 2),(1, 3)],\n","              'vectorizer__min_df': [0.,.2,.4,.6,.8,1],\n","              'classifier__penalty': ('l1','l2'),\n","              'classifier__C': (range(1,10,2)),\n","             }\n","\n","clf_pipeline_LogitReg = Pipeline(\n","            [(\"vectorizer\", TfidfVectorizer()),\n","            (\"classifier\", LogisticRegression())]\n","        )\n","\n","rndgs_clf_LogitReg = RandomizedSearchCV(clf_pipeline_LogitReg, parameters, scoring='f1', cv = 4, n_jobs=-1)\n","rndgs_clf_LogitReg.fit(X_train, y_train)\n","\n","probs = rndgs_clf_LogitReg.predict_proba(X_train)[:,1]\n","plotROC(y_train, probs, 'Train')\n","\n","probs = rndgs_clf_LogitReg.predict_proba(X_test)[:,1]\n","plotROC(y_test, probs, 'Test')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(metrics.classification_report(y_test, rndgs_clf_LogitReg.predict(X_test)))\n","f1_rndLogR_2 = metrics.f1_score(y_test, rndgs_clf_LogitReg.predict(X_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.DataFrame([f1_base, f1_gsLSVC, f1_rndLogR, f1_rndLogR_2], index=['BaseLine', 'GS_LSVC', 'rndGS_LogR', 'rndGS_LogR_Adj'], columns=['f1 score'])"]},{"cell_type":"markdown","metadata":{},"source":["## Baseline algorithm looks simple and good enough. The Confusion Matrix isn't bad too. Howewer, the Logistic Regression forecasts probubilities of classification. Hence, we are able to plot Reciever Operator Curve (ROC) and get AUC (Area under Curve) value. It may be a useful for the next improvements of this notebook."]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.6 ('venv': venv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"c3856cf89b4f4a5a2e88768fea4ed6a782b3dc08f6f2d4dce94f9b2781782513"}}},"nbformat":4,"nbformat_minor":4}
